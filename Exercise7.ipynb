{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/robitussin/CCDEPLRL_EXERCISES/blob/main/Exercise7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Exercise 7\n",
        "\n",
        "Text Generation using LSTM"
      ],
      "metadata": {
        "id": "b6IEc4ScWrPh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, Bidirectional\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import regularizers\n",
        "import tensorflow.keras.utils as ku\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "kM9X6KKBWNdJ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = Tokenizer()\n",
        "\n",
        "!wget --no-check-certificate \\\n",
        "    https://raw.githubusercontent.com/cibernox/storyteller/refs/heads/master/snow-white.txt \\\n",
        "    -O /tmp/snowwhite.txt\n",
        "\n",
        "data = open('/tmp/snowwhite.txt').read()"
      ],
      "metadata": {
        "id": "LqlQti1gc8uU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRnDnCW-Z7qv"
      },
      "source": [
        "corpus = data.lower().split(\"\\n\")\n",
        "\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "total_words = len(tokenizer.word_index) + 1\n",
        "\n",
        "# create input sequences using list of tokens\n",
        "input_sequences = []\n",
        "for line in corpus:\n",
        "\ttoken_list = tokenizer.texts_to_sequences([line])[0]\n",
        "\tfor i in range(1, len(token_list)):\n",
        "\t\tn_gram_sequence = token_list[:i+1]\n",
        "\t\tinput_sequences.append(n_gram_sequence)\n",
        "\n",
        "\n",
        "# pad sequences\n",
        "max_sequence_len = max([len(x) for x in input_sequences])\n",
        "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
        "\n",
        "# create predictors and label\n",
        "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
        "\n",
        "label = ku.to_categorical(label, num_classes=total_words)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create the LSTM model"
      ],
      "metadata": {
        "id": "Xs9MEXQlgRi6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Build an LSTM"
      ],
      "metadata": {
        "id": "n9rk_hx4WXNh"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1fXTEO3GJ282",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "8cab10a4-7f35-48b5-eb38-32d1de2015cc"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(# Your Embedding Layer)\n",
        "model.add(# An LSTM Layer)\n",
        "model.add(# A dropout layer)\n",
        "model.add(# Another LSTM Layer)\n",
        "model.add(# A Dense Layer including regularizers)\n",
        "model.add(# A Dense Layer)\n",
        "# Pick an optimizer\n",
        "model.compile(# Pick a loss function and an optimizer)\n",
        "print(model.summary())"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "incomplete input (<ipython-input-39-bc12242fa1b7>, line 10)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-39-bc12242fa1b7>\"\u001b[0;36m, line \u001b[0;32m10\u001b[0m\n\u001b[0;31m    print(model.summary())\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m incomplete input\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AIg2f1HBxqof"
      },
      "source": [
        " history = model.fit(predictors, label, epochs=100, verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = history.history['accuracy']\n",
        "loss = history.history['loss']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "plt.plot(epochs, acc, 'b', label='Training accuracy')\n",
        "plt.title('Training accuracy')\n",
        "\n",
        "plt.figure()\n",
        "\n",
        "plt.plot(epochs, loss, 'b', label='Training Loss')\n",
        "plt.title('Training loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "drHghkbTgjFV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## B. Generate texts\n"
      ],
      "metadata": {
        "id": "tMHnWkJfgJM6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. \"Snow White lived in the forest with...\""
      ],
      "metadata": {
        "id": "3LIIaWv2ebM4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# put your answer here"
      ],
      "metadata": {
        "id": "stD4cuaZeZBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. \"The queen looked into the mirror and said...\""
      ],
      "metadata": {
        "id": "pmIing2celug"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# put your answer here"
      ],
      "metadata": {
        "id": "bxbCA1u0emDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. \"One day, Snow White found a small cottage and...\""
      ],
      "metadata": {
        "id": "8ueR_ks6eq3H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# put your answer here"
      ],
      "metadata": {
        "id": "LQVtpbmperOc"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}